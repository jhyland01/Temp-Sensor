{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | numerical_linear | Sequential | 1.2 K \n",
      "1 | rnn              | GRU        | 445 K \n",
      "2 | linear_out       | Sequential | 33.3 K\n",
      "3 | loss             | MSELoss    | 0     \n",
      "------------------------------------------------\n",
      "479 K     Trainable params\n",
      "0         Non-trainable params\n",
      "479 K     Total params\n",
      "1.919     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489679e78b2941aca3a2a0db8eeeab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnny/anaconda3/envs/kaggle/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/johnny/anaconda3/envs/kaggle/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3bde53ee5b4c6a82d1b10eb414f601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb4d511fbde488d9dcf8000a2fc3a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a20f1d3b554ba7a88ebb7e169f8fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.733\n",
      "/Users/johnny/anaconda3/envs/kaggle/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 214\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m# Test the model\u001b[39;00m\n\u001b[1;32m    213\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 214\u001b[0m y_pred \u001b[39m=\u001b[39m model(X_test_tensor)\n\u001b[1;32m    215\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    216\u001b[0m y_pred \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 153\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 153\u001b[0m     numerical_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumerical_linear(x)\n\u001b[1;32m    154\u001b[0m     output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(numerical_embedding)\n\u001b[1;32m    155\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_out(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# config\n",
    "config = {\n",
    "    \"data_path\": \"../\",\n",
    "    \"model\": {\n",
    "        \"encoder_name\": \"timm-resnest26d\",\n",
    "        \"loss_smooth\": 1.0,\n",
    "        \"optimizer_params\": {\"lr\": 0.003, \"weight_decay\": 0.0},\n",
    "        \"scheduler\": {\n",
    "            \"name\": \"CosineAnnealingLR\",\n",
    "            \"params\": {\n",
    "                \"CosineAnnealingLR\": {\"T_max\": 50, \"eta_min\": 1e-06, \"last_epoch\": -1},\n",
    "                \"ReduceLROnPlateau\": {\n",
    "                    \"factor\": 0.316,\n",
    "                    \"mode\": \"min\",\n",
    "                    \"patience\": 3,\n",
    "                    \"verbose\": True,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"seg_model\": \"Unet\",\n",
    "    },\n",
    "    \"output_dir\": \"models\",\n",
    "    \"progress_bar_refresh_rate\": 500,\n",
    "    \"seed\": 42,\n",
    "    \"train_bs\": 128,\n",
    "    \"trainer\": {\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"max_epochs\": 50,\n",
    "        \"min_epochs\": 20,\n",
    "        \"accelerator\": \"mps\",\n",
    "        \"devices\": 1,\n",
    "    },\n",
    "    \"valid_bs\": 128,\n",
    "    \"workers\": 0,\n",
    "    \"device\": \"mps\",\n",
    "    \"folds\": {\n",
    "        \"n_splits\": 4,\n",
    "        \"random_state\": 42,\n",
    "        \"train_folds\": [0, 1, 2, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/single_turbine_data/train_reduced_unskewed.csv')\n",
    "test = pd.read_csv('data/single_turbine_data/test_reduced_unskewed.csv')\n",
    "\n",
    "label = ['1_Gear oil temperature (°C)']\n",
    "\n",
    "X_train = train.drop(label, axis=1)\n",
    "y_train = train[label]\n",
    "X_test = test.drop(label, axis=1)\n",
    "y_test = test[label]\n",
    "\n",
    "# convert to datetime\n",
    "X_train['# Date and time'] = pd.to_datetime(X_train['# Date and time'])\n",
    "X_test['# Date and time'] = pd.to_datetime(X_test['# Date and time'])\n",
    "\n",
    "# Setting the index\n",
    "X_train.set_index('# Date and time', inplace=True)\n",
    "X_test.set_index('# Date and time', inplace=True)\n",
    "\n",
    "original_cols = [\n",
    "    # '1_Wind direction (°)',\n",
    "    #    '1_Nacelle position (°)', \n",
    "       '1_Power (kW)',\n",
    "       '1_Front bearing temperature (°C)', '1_Rear bearing temperature (°C)',\n",
    "       '1_Stator temperature 1 (°C)', '1_Nacelle ambient temperature (°C)',\n",
    "       '1_Nacelle temperature (°C)', '1_Transformer temperature (°C)',\n",
    "       '1_Generator bearing rear temperature (°C)',\n",
    "       '1_Generator bearing front temperature (°C)', '1_Temp. top box (°C)',\n",
    "       '1_Hub temperature (°C)', '1_Ambient temperature (converter) (°C)',\n",
    "       '1_Rotor bearing temp (°C)', '1_Transformer cell temperature (°C)', '1_Generator RPM (RPM)']\n",
    "extras = ['month_sin', 'month_cos', 'hour_sin', 'hour_cos', \n",
    "'curtailed', \n",
    "'offline',\n",
    "]\n",
    "\n",
    "cols = original_cols\n",
    "X_test = X_test[cols]\n",
    "X_train = X_train[cols]\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "import lightning.pytorch as pl\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "# Reshape data for sequence model (e.g., RNN, GRU, LSTM)\n",
    "sequence_length = 10  # Define the sequence length\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        sequences.append(seq)\n",
    "    return torch.stack(sequences)\n",
    "\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "X_train_seq = create_sequences(X_train_tensor, sequence_length)\n",
    "y_train_seq = create_sequences(y_train_tensor, sequence_length)\n",
    "X_test_seq = create_sequences(X_test_tensor, sequence_length)\n",
    "y_test_seq = create_sequences(y_test_tensor, sequence_length)\n",
    "\n",
    "train_dataset_seq = TensorDataset(X_train_seq, y_train_seq)\n",
    "train_loader_seq = DataLoader(train_dataset_seq, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset_seq = TensorDataset(X_test_seq, y_test_seq)\n",
    "test_loader_seq = DataLoader(test_dataset_seq, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# Define Neural Network\n",
    "class LightningModule(pl.LightningModule):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.LayerNorm(64)\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.GRU(64, 128,\n",
    "                          num_layers=2, \n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "        \n",
    "        self.linear_out  = nn.Sequential(\n",
    "            nn.Linear(128 * 2, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, output_dim))\n",
    "        \n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        numerical_embedding = self.numerical_linear(x)\n",
    "        output, _ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters())\n",
    "\n",
    "        if self.config['model'][\"scheduler\"][\"name\"] == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                **self.config['model'][\"scheduler\"][\"params\"][self.config['model'][\"scheduler\"][\"name\"]],\n",
    "            )\n",
    "            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n",
    "        elif self.config['model'][\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\":\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                **self.config['model'][\"scheduler\"][\"params\"][self.config['model'][\"scheduler\"][\"name\"]],\n",
    "            )\n",
    "            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat.reshape(-1, y_hat.shape[-1]), y.reshape(-1, y.shape[-1]))\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        for param_group in self.trainer.optimizers[0].param_groups:\n",
    "            lr = param_group[\"lr\"]\n",
    "        self.log(\"lr\", lr, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        logs = {\"train_loss\": loss, \"lr\": lr}\n",
    "        return {\"loss\": loss, \"log\": logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, verbose=1)\n",
    "progress_bar_callback = TQDMProgressBar(refresh_rate=config[\"progress_bar_refresh_rate\"])\n",
    "\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        callbacks=[early_stop_callback, progress_bar_callback],\n",
    "         logger=logger, **config[\"trainer\"]\n",
    "    )\n",
    "\n",
    "# Train the model\n",
    "model = LightningModule(X_train.shape[1], y_train.shape[1]).to(torch.device('mps'))\n",
    "trainer.fit(model, train_loader_seq, test_loader_seq)\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "y_pred = model(X_test_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# unscale the data\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import Path\n",
    "# Save results\n",
    "results_file = Path('results.csv')\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        'Model': 'Neural Network',\n",
    "        'Training RMSE': trainer.logged_metrics['train_loss'].item(),\n",
    "        'Validation RMSE': trainer.logged_metrics['val_loss'].item(),\n",
    "        'Iterations': trainer.global_step,\n",
    "        'Learning Rate': config['model']['optimizer_params']['lr'],\n",
    "        'Depth': [X_train.shape[1], 64, 64, y_train.shape[1]],\n",
    "        'Loss Function': 'MSE',\n",
    "        'Features': ', '.join(cols),\n",
    "    }\n",
    ")\n",
    "\n",
    "if results_file.exists():\n",
    "    existing_df = pd.read_csv(results_file)\n",
    "    results_df = pd.concat([existing_df, results_df])\n",
    "\n",
    "results_df.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access logged metrics\n",
    "train_loss = trainer.logged_metrics['train_loss']\n",
    "val_loss = trainer.logged_metrics['val_loss']\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "y_pred = model(X_test_tensor)\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# unscale the data\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('data/single_turbine_data/train_reduced_unskewed.csv')\n",
    "\n",
    "label = ['1_Gear oil temperature (°C)']\n",
    "\n",
    "y_train = train[label].values\n",
    "\n",
    "# Assuming y_pred and y_true are your prediction and ground truth numpy arrays\n",
    "\n",
    "# Compute statistics of ground truth and predictions\n",
    "mean_true = np.mean(y_train)\n",
    "std_true = np.std(y_train)\n",
    "\n",
    "mean_pred = np.mean(y_pred)\n",
    "std_pred = np.std(y_pred)\n",
    "\n",
    "# Rescale predictions\n",
    "y_pred_rescaled = ((y_pred - mean_pred) / std_pred) * std_true + mean_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, y_pred_rescaled))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(y_pred_rescaled, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacakthon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
